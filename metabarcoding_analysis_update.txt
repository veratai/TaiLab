## general steps for initial analysis of metabarcode data through qiime2 (Tai Lab)

##check data quality using FastQC
## check some of them, do not have to do all
mkdir fastqc_out
fastqc -t 4 /data/seqarchive/sunfish_cyano16S_108F377R/file.fastq -o fastqc_out/

## trim adapters/primers from sequences

#trim off bad quality, and adapters from paired-end reads
#-q quality cutoff, 3' and 5' ends
#-n maximum number of times adapter will be removed
#-m minimum read length
#-e error-rate by default is 0.1, so for 20 nt primer allows for 2 mismatches
#-a 3' adapter on first read (= rev comp. of reverse primer (CYAN377R_VT = CCCATKGCGGAARATTCCCC)
#-A 3' adapter on paired read (= rev comp. of forward primer (CYAN108F = ACGGGTGAGTAACRCGTRA))

cutadapt -q 15,15 -n 1 -m 100 -a GGGGAATYTTCCGCMATGGG -A TYACGYGTTACTCACCCGT -o out1_cutadapt.fastq -p out2_cutadapt.fastq in1.fastq in2.fastq

##or import sequences into qiime, then use cutadapt to check for adapter sequences on the 3' end of reads, meaning PCR product was short and sequence read went through to the 3' end of the PCR product
#p-adapter-f is looking for the reverse primer on the 3' end of the first, forward read - so need to enter the reverse complement of the reverse primer e.g. reverse complement of CYAN377R_VT = CCCATKGCGGAARATTCCCC
#p-adapter-r is looking for the forward primer on the 3' end of the second, reverse read - so need to enter the reverse complement of the forward primer e.g. reverse complement of CYAN108F = ACGGGTGAGTAACRCGTRA
#cut adapters
qiime cutadapt trim-paired
--i-demultiplexed-sequences 16Sseqs_demux.qza
--p-adapter-f GGGGAATYTTCCGCMATGGG
--p-adapter-r TYACGYGTTACTCACCCGT
--o-trimmed-sequences 16Sseqs_cutadapt.qza
--output-dir cutadapt_results


****
#to transfer files from cardinal to local Mac/Unix

#change directory to where you want the files copied, or specify directory

scp username@cardinal.biology.uwo.ca:~/path/to/file ./

#Or can download FileZilla

****

#using qiime2

#activate qiime2 environment
source activate qiime2-2019.4

#now updated to version 2022.2 - so code may need to be adjusted to account for new version
source activate qiime2-2022.2


#enable tab completion
source tab-qiime

#to deactivate qiime
source deactivate

#import paired-end sequences, 2 files per sample (forward and reverse)
#need manifest file
#The manifest file is tab-separated, specifying path to the fastq files:

sample-id     forward-absolute-filepath       reverse-absolute-filepath
sample-1   filepath/seqs_R1.fastq.gz   filepath/seqs_R2.fastq.gz

#import the sequences
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path manifestfile_sunfish_cyano16S.csv \
  --output-path paired-end-demux.qza \
  --source-format PairedEndFastqManifestPhred33V2

##updated:
qiime tools import \
  --type 'SampleData[PairedEndSequencesWithQuality]' \
  --input-path Calvert_ABSWGW_manifest.txt \
  --output-path Calvert_ABSWGW_cutadapt_demux.qza \
  --input-format PairedEndFastqManifestPhred33V2

# or for single end data
qiime tools import \
  --type 'SampleData[SequencesWithQuality]' \
  --input-path manifestfile_sunfish_cyano16S.csv \
  --output-path mergedsingleend_sunfishcyano16S_demux.qza \
  --source-format SingleEndFastqManifestPhred33V2

#get summary of imported sequences
qiime demux summarize \
  --i-data mergedsingleend_sunfishcyano16S_demux.qza \
  --o-visualization mergedsingleend_sunfishcyano16S_demux.qzv

##can do cutadapt step here, if didn't do previously
#use cutadapt to check for adapter sequences on the 3' end of reads, meaning PCR product was short and sequence read went through to the 3' end of the PCR product

#p-adapter-f is looking for the reverse primer on the 3' end of the first, forward read - so need to enter the reverse complement of the reverse primer e.g. reverse complement of CYAN377R_VT = CCCATKGCGGAARATTCCCC

#p-adapter-r is looking for the forward primer on the 3' end of the second, reverse read - so need to enter the reverse complement of the forward primer e.g. reverse complement of CYAN108F = ACGGGTGAGTAACRCGTRA
#cut adapters
qiime cutadapt trim-paired
--i-demultiplexed-sequences 16Sseqs_demux.qza
--p-adapter-f GGGGAATYTTCCGCMATGGG
--p-adapter-r TYACGYGTTACTCACCCGT
--o-trimmed-sequences 16Sseqs_cutadapt.qza
--output-dir cutadapt_results




#determine how much of 5' and 3' ends need to be trimmed based on quality cut-off
qiime tools view 16Sseqs_cutadapt.qza

#view/examine output by opening .qzv files with the qiime2 viewer on the web (https://view.qiime2.org/)
#look at interactive quality plot for seq quality for F and R reads

#trim seqs (de-noise), de-replicate, merge, remove chimeras using dada2 (https://benjjneb.github.io/dada2/index.html)
#do not trim so much for paired reads so that seqs do not merge anymore
#but probably will not have to trim much, because used cutadapt before to remove primer seqs and quality trim ends

qiime dada2 denoise-paired \
  --i-demultiplexed-seqs mergedsingleend_sunfishcyano16S_demux.qza \
  --o-table table_sunfish_cyano16S \
  --o-representative-sequences repseqs_sunfish_cyano16S \
  --p-trim-left-f 13 \
  --p-trim-left-r 13 \
  --p-trunc-len-f 150 \
  --p-trunc-len-r 150 \
  --p-n-threads 15
  
 --o-denoising-stats dada2stats_sunfish_cyano16S
 
#generates table_sunfish_cyano16S.qza and repseqs_sunfish_cyano16S.qza files
#get/view summary of data


#now here need sample metadata table
#as tab-separated file, must have columns (or may not be necessary anymore with new version of qiime):
#  #SampleID	BarcodeSequence	LinkerPrimerSequence


#Examine results, then need to filter out low frequency ASVs

#Look at the distribution of the number of sequence reads assigned to each ASV, and the number of sequence reads associated with each sample.

qiime feature-table summarize \
  --i-table table_sunfish_cyano16S.qza \
  --o-visualization table_sunfish_cyano16S.qzv \
  --m-sample-metadata-file metadata_sunfish.tsv

qiime tools view table.qzv

qiime feature-table tabulate-seqs \
  --i-data repseqs_sunfish_cyano16S.qza \
  --o-visualization repseqs_sunfish_cyano16S.qzv

qiime tools view rep-seqs.qzv

#filter feature table based on the distribution of reads for each feature
# using first quartile for these data is good as a cut-off
# here using 7 seqs per ASV as a cutoff

qiime feature-table filter-features \
   --i-table table_sunfish_cyano16S.qza \
   --p-min-frequency 7 \
   --p-min-samples 1 \
   --o-filtered-table table_filtered_ASVmin7sunfish_cyano16S.qza


#didn't do this here, but:
#remove samples that have too few reads
qiime feature-table filter-samples
	--i-table table_filtered_ASVmin7sunfish_cyano16S.qza
	--p-min-frequency 500
	--o-filtered-table table_filtered_ASVmin7_samplemin500_sunfish_cyano16S.qza


qiime feature-table summarize \
  --i-table table_filtered_ASVmin7sunfish_cyano16S.qza \
  --o-visualization table_filtered_ASVmin7sunfish_cyano16S.qzv \
  --m-sample-metadata-file metadata_sunfish.txt

#filter rep-seqs file

qiime feature-table filter-seqs \
  --i-data repseqs_sunfish_cyano16S.qza \
  --i-table table_filtered_ASVmin7sunfish_cyano16S.qza \
  --o-filtered-data repseqs_sunfish_cyano16S_ASVmin7.qza

#generate phylogenetic tree
#align with mafft
qiime alignment mafft \
  --i-sequences repseqs_sunfish_cyano16S.qza \
  --o-alignment repseqs_sunfish_cyano16S_aligned.qza

#mask highly variable sites
qiime alignment mask \
  --i-alignment repseqs_sunfish_cyano16S_aligned.qza \
  --o-masked-alignment repseqs_sunfish_cyano16S_aligned_masked.qza

#generate tree with FastTree
qiime phylogeny fasttree \
  --i-alignment repseqs_sunfish_cyano16S_aligned_masked.qza \
  --o-tree repseqs_sunfish_cyano16S_unrooted_tree.qza

#apply midpoint rooting
qiime phylogeny midpoint-root \
  --i-tree repseqs_sunfish_cyano16S_unrooted_tree.qza \
  --o-rooted-tree repseqs_sunfish_cyano16S_rooted_tree.qza

#calculate alpha and beta diversity metrics
#choose p-sampling-depth based on #reads per sample, as seen is table.qzv
#choose depth as the number of reads in the sample with the fewest reads

qiime diversity core-metrics-phylogenetic \
  --i-phylogeny repseqs_sunfish_cyano16S_rooted_tree.qza \
  --i-table table_filtered_ASVmin7sunfish_cyano16S.qza \
  --p-sampling-depth 1109 \
  --m-metadata-file metadata_sunfish.tsv \
  --output-dir core-metrics-results

#can do stats analyses on these results
#will also want to consider compositional analyses instead of rarefying (p-sampling-depth)


#taxonomic analysis

#need trained dataset

qiime feature-classifier classify-sklearn \
  --i-classifier gg-13-8-99-515-806-nb-classifier.qza \
  --i-reads repseqs_sunfish_cyano16S_ASVmin7.qza \
  --o-classification taxonomy_sunfish_cyano16S_ASVmin7.qza

qiime metadata tabulate \
  --m-input-file taxonomy_sunfish_cyano16S_ASVmin7.qza \
  --o-visualization taxonomy_sunfish_cyano16S_ASVmin7.qzv


#generate taxonomy bar plots

qiime taxa barplot \
  --i-table sunfish_cyano16S_filteredtable_ASVmin7.qza \
  --i-taxonomy taxonomy_sunfish_cyano16S_ASVmin7.qza \
  --m-metadata-file metadata_sunfish.txt \
  --o-visualization taxa_barplots_sunfish_cyano16S_ASVmin7.qzv


#use qiime tools export to export data out of qiime

#eg. to export table into BIOM v2.1.0 format
qiime tools export \
  --input-path feature-table.qza \
  --output-path exported-feature-table
#generates feature-table.biom

#export taxonomy to tsv table
qiime tools export --input-path taxonomy.qza --output-path ./
#generates taxonomy.tsv
#using nano, change header from: Feature ID	Taxon	Confidence
#to:
#OTUID	taxonomy	confidence 

#add taxonomy to OTU table in BIOM format
biom add-metadata -i feature-table.biom -o table-with-taxonomy.biom --observation-metadata-fp taxonomy.tsv --sc-separated taxonomy

#then convert BIOM format to tsv
biom convert -i feature-table.biom -o feature-table.tsv --to-tsv

biom add-metadata -i WestBeachSand_18SV4_table97_min5.biom -o tabletax.biom --observation-metadata-fp WestBeachSand_18SV4_rep_seqs97_min5_taxonomy.tsv --sc-separated taxonomy
biom convert -i tabletax.biom -o tabletax.tsv --to-tsv --header-key taxonomy
 
#eg. to export newick tree
qiime tools export \
  --input-path unrooted-tree.qza \
  --output-path exported-tree

#convert from biom format to .txt


